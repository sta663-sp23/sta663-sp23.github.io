cmap=plt.cm.gray_r, origin='lower',
vmax=log_z.min() + 1.5*log_z.ptp()
)
contours = plt.contour(
log_z,
levels=levels.get(f, None),
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gnuplot, origin='lower'
)
levels[f] = contours.levels
plt.clabel(contours, inline=1, fmt=super_fmt, fontsize=14)
def super_fmt(value):
if value > 1:
if np.abs(int(value) - value) < .1:
out = '$10^{%.1i}$' % value
else:
out = '$10^{%.1f}$' % value
else:
value = np.exp(value - .01)
if value > .1:
out = '%1.1f' % value
elif value > .01:
out = '%.2f' % value
else:
out = '%.2e' % value
return out
def plot_2d_traj(x, y, f, traj=None, title="", figsize=(4,4)):
x_min, x_max = -1, 2
y_min, y_max = 2.25/3*x_min - .2, 2.25/3*x_max - .2
plt.figure(figsize=figsize, layout="constrained")
x, y = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]
x = x.T
y = y.T
plt.figure(figsize=figsize)
#plt.clf()
plt.axes([0, 0, 1, 1])
X = np.concatenate((x[np.newaxis, ...], y[np.newaxis, ...]), axis=0)
z = np.apply_along_axis(f, 0, X)
log_z = np.log(z + .01)
plt.imshow(
log_z,
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gray_r, origin='lower',
vmax=log_z.min() + 1.5*log_z.ptp()
)
contours = plt.contour(
log_z,
levels=levels.get(f, None),
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gnuplot, origin='lower'
)
levels[f] = contours.levels
plt.clabel(contours, inline=1, fmt=super_fmt, fontsize=14)
f, grad, hess = mk_quad(0.7)
plot_2d_traj((0,1), (0,1), f)
def super_fmt(value):
if value > 1:
if np.abs(int(value) - value) < .1:
out = '$10^{%.1i}$' % value
else:
out = '$10^{%.1f}$' % value
else:
value = np.exp(value - .01)
if value > .1:
out = '%1.1f' % value
elif value > .01:
out = '%.2f' % value
else:
out = '%.2e' % value
return out
def plot_2d_traj(x, y, f, traj=None, title="", figsize=(4,4)):
x_min, x_max = -1, 2
y_min, y_max = 2.25/3*x_min - .2, 2.25/3*x_max - .2
plt.figure(figsize=figsize, layout="constrained")
x, y = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]
x = x.T
y = y.T
plt.figure(figsize=figsize)
#plt.clf()
plt.axes([0, 0, 1, 1])
X = np.concatenate((x[np.newaxis, ...], y[np.newaxis, ...]), axis=0)
z = np.apply_along_axis(f, 0, X)
log_z = np.log(z + .01)
plt.imshow(
log_z,
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gray_r, origin='lower',
vmax=log_z.min() + 1.5*log_z.ptp()
)
contours = plt.contour(
log_z,
#levels=levels.get(f, None),
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gnuplot, origin='lower'
)
#levels[f] = contours.levels
plt.clabel(contours, inline=1, fmt=super_fmt, fontsize=14)
f, grad, hess = mk_quad(0.7)
plot_2d_traj((0,1), (0,1), f)
x0 = (1.6, 1.1)
x_i, y_i = x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
for i in range(max_step):
dx_i, dy_i = grad(np.array([x_i, y_i]))
for j in range(max_back):
new_x_i = x - dx_i * step
new_y_i = y - dy_i * step
new_f_i = f((new_x_i, new_y_i))
if (new_f_i < all_f_i[-1]):
break
step = step * tau
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_x_i.append(y_i)
all_f_i.append(f_i)
if np.sqrt(dx_i**2 + dy_i**2) < tol:   #<<
break
max_back=10
x_i, y_i = x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
for i in range(max_step):
dx_i, dy_i = grad(np.array([x_i, y_i]))
for j in range(max_back):
new_x_i = x - dx_i * step
new_y_i = y - dy_i * step
new_f_i = f((new_x_i, new_y_i))
if (new_f_i < all_f_i[-1]):
break
step = step * tau
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_x_i.append(y_i)
all_f_i.append(f_i)
if np.sqrt(dx_i**2 + dy_i**2) < tol:   #<<
break
x_i, y_i = x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
for i in range(max_step):
dx_i, dy_i = grad(np.array([x_i, y_i]))
for j in range(max_back):
new_x_i = x - dx_i * step
new_y_i = y - dy_i * step
new_f_i = f((new_x_i, new_y_i))
if (new_f_i < all_f_i[-1]):
break
step = step * tau
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_x_i.append(y_i)
all_f_i.append(f_i)
if np.sqrt(dx_i**2 + dy_i**2).sum() < tol:   #<<
break
all_x_i
x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
grad(np.array([x_i, y_i]))
grad
f, grad, hess = mk_quad(0.7)
grad
grad((x_i, y_i))
grad([x_i, y_i])
# Code from https://scipy-lectures.org/ on optmization
def mk_quad(epsilon, ndim=2):
def f(x):
x = np.asarray(x)
y = x.copy()
y *= np.power(epsilon, np.arange(ndim))
return .33*np.sum(y**2)
def f_prime(x):
x = np.asarray(x)
y = x.copy()
scaling = np.power(epsilon, np.arange(ndim))
y *= scaling
return .33*2*scaling*y
def hessian(x):
scaling = np.power(epsilon, np.arange(ndim))
return .33*2*np.diag(scaling)
return f, f_prime, hessian
f, grad, hess = mk_quad(0.7)
grad((1,1))
grad((1.,1.))
x_i, y_i = x0
x_i
y_i
grad([x_i, y_i])
dx_i, dy_i = grad([x_i, y_i])
dx_i
dy_u
dy_i
new_x_i = x - dx_i * step
new_y_i = y - dy_i * step
new_f_i = f((new_x_i, new_y_i))
new_f_i
all_f_i[-1]
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
all_f_i
new_f_i
new_f_i < all_f_i[-1]
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_x_i.append(y_i)
all_f_i.append(f_i)
np.sqrt(dx_i**2 + dy_i**2).sum()
np.sqrt(dx_i**2 + dy_i**2).sum() < tol
def grad_desc_2d(x0, f, grad, step, tau=0.5, max_step=100, max_back=10, tol = 1e-6):
x_i, y_i = x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
for i in range(max_step):
dx_i, dy_i = grad([x_i, y_i])
for j in range(max_back):
new_x_i = x - dx_i * step
new_y_i = y - dy_i * step
new_f_i = f((new_x_i, new_y_i))
if (new_f_i < all_f_i[-1]):
break
step = step * tau
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_x_i.append(y_i)
all_f_i.append(f_i)
if np.sqrt(dx_i**2 + dy_i**2).sum() < tol:   #<<
break
return all_x_i, all_y_i, all_f_i
f, grad, hess = mk_quad(0.7)
opt = grad_desc_2d((1.6, 1.1), f, grad, step=1)
plot_2d_traj((-1,2), (-1,2), f, title="$\\epsilon=0.7$", traj=opt)
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
plt.rcParams['figure.dpi'] = 200
from scipy import optimize
def grad_desc_1d(x, f, grad, step, max_step=100, tol = 1e-6):
all_x_i = [x]
all_f_i = [f(x)]
try:
for i in range(max_step):
dx = grad(x)
x += step * (-dx)
f_x = f(x)
all_x_i.append(x)
all_f_i.append(f_x)
if np.abs(dx) < tol:
break
except OverflowError as err:
print(f"{type(err).__name__}: {err}")
if len(all_x_i) == max_step+1:
print("Warning - Failed to converge!")
return all_x_i, all_f_i
def plot_1d_traj(x, f, traj, title="", figsize=(5,3)):
plt.figure(figsize=figsize, layout="constrained")
x_range = x[1]-x[0]
x_focus = np.linspace(x[0], x[1], 101)
x_ext = np.linspace(x[0]-0.2*x_range, x[1]+0.2*x_range, 141)
plt.plot(x_focus, f(x_focus), "-k")
xlim = plt.xlim()
ylim = plt.ylim()
plt.plot(x_ext, f(x_ext), "-k")
plt.plot(traj[0], traj[1], ".-b", ms = 10)
plt.xlim(xlim)
plt.ylim(ylim)
plt.show()
plt.close('all')
f = lambda x: x**2
grad = lambda x: 2*x
opt = grad_desc_1d(-2, lambda x: x**2, lambda x: 2*x, step=0.25)
plot_1d_traj(
(-2, 2), lambda x: x**2, opt
)
opt = grad_desc_1d(-2, lambda x: x**2, lambda x: 2*x, step=0.5)
plot_1d_traj(
(-2, 2), lambda x: x**2, opt
)
opt = grad_desc_1d(-2, f, grad, step=0.9)
plot_1d_traj( (-2,2), f, opt )
opt = grad_desc_1d(-2, f, grad, step=1)
plot_1d_traj( (-2,2), f, opt )
f = lambda x: x**4 + x**3 - x**2 - x
grad = lambda x: 4*x**3 + 3*x**2 - 2*x - 1
opt = grad_desc_1d(-1.5, f, grad, step=0.2)
plot_1d_traj( (-1.5, 1.5), f, opt )
opt = grad_desc_1d(-1.5, f, grad, step=0.25)
plot_1d_traj( (-1.5, 1.5), f, opt)
opt = grad_desc_1d(1.5, f, grad, step=0.2)
plot_1d_traj( (-1.5, 1.5), f, opt )
opt = grad_desc_1d(1.25, f, grad, step=0.2)
plot_1d_traj( (-1.5, 1.5), f, opt)
opt = grad_desc_1d(-1.5, f, grad, step=0.75)
plot_1d_traj( (-1.5, 1.5), f, opt )
opt = grad_desc_1d(1.5, f, grad, step=0.25)
plot_1d_traj( (-1.5, 1.5), f, opt)
def grad_desc_1d_bt(x, f, grad, step, tau=0.5, max_step=100, max_back=10, tol = 1e-6):
all_x_i = [x]
all_f_i = [f(x)]
try:
for i in range(max_step):
dx = grad(x)
for j in range(max_back):        #<<
new_x = x + step * (-dx)       #<<
new_f_x = f(new_x)             #<<
#<<
if (new_f_x < all_f_i[-1]):    #<<
break                        #<<
#<<
step = step * tau              #<<
x = new_x
f_x = new_f_x
all_x_i.append(x)
all_f_i.append(f_x)
if np.abs(dx) < tol:
break
except OverflowError as err:
print(f"{type(err).__name__}: {err}")
if len(all_x_i) == max_step+1:
print("Warning - Failed to converge!")
return all_x_i, all_f_i
opt = grad_desc_1d_bt(-1.5, f, grad, step=0.75, tau=0.5)
plot_1d_traj( (-1.5, 1.5), f, opt )
opt = grad_desc_1d_bt(1.5, f, grad, step=0.25, tau=0.5)
plot_1d_traj( (-1.5, 1.5), f, opt)
# Code from https://scipy-lectures.org/ on optmization
def mk_quad(epsilon, ndim=2):
def f(x):
x = np.asarray(x)
y = x.copy()
y *= np.power(epsilon, np.arange(ndim))
return .33*np.sum(y**2)
def f_prime(x):
x = np.asarray(x)
y = x.copy()
scaling = np.power(epsilon, np.arange(ndim))
y *= scaling
return .33*2*scaling*y
def hessian(x):
scaling = np.power(epsilon, np.arange(ndim))
return .33*2*np.diag(scaling)
return f, f_prime, hessian
def super_fmt(value):
if value > 1:
if np.abs(int(value) - value) < .1:
out = '$10^{%.1i}$' % value
else:
out = '$10^{%.1f}$' % value
else:
value = np.exp(value - .01)
if value > .1:
out = '%1.1f' % value
elif value > .01:
out = '%.2f' % value
else:
out = '%.2e' % value
return out
def plot_2d_traj(x, y, f, traj=None, title="", figsize=(5,5)):
x_min, x_max = x
y_min, y_max = y
plt.figure(figsize=figsize, layout="constrained")
x, y = np.mgrid[x_min:x_max:100j, y_min:y_max:100j]
x = x.T
y = y.T
plt.figure(figsize=figsize)
#plt.clf()
#plt.axes([0, 0, 1, 1])
X = np.concatenate((x[np.newaxis, ...], y[np.newaxis, ...]), axis=0)
z = np.apply_along_axis(f, 0, X)
log_z = np.log(z + .01)
plt.imshow(
log_z,
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gray_r, origin='lower',
vmax=log_z.min() + 1.5*log_z.ptp()
)
contours = plt.contour(
log_z,
extent=[x_min, x_max, y_min, y_max],
cmap=plt.cm.gnuplot, origin='lower'
)
plt.clabel(contours, inline=1, fmt=super_fmt, fontsize=12)
if not traj is None:
plt.plot(traj[0], traj[1], ".-b", ms = 10)
if not title == "":
plt.title(title)
plt.show()
f, grad, hess = mk_quad(0.7)
plot_2d_traj((-1,2), (-1,2), f, title="$\\epsilon=0.7$")
f, grad, hess = mk_quad(0.02)
plot_2d_traj((-1,2), (-1,2), f, title="$\\epsilon=0.02$")
f, grad, hess = mk_quad(0.7)
opt = grad_desc_2d((1.6, 1.1), f, grad, step=1)
opt
x0 = (1.6, 1.2)
f
grad
step
tau
tau=0.5
max_step=100
max_back=10
tol = 1e-6
x_i, y_i = x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
grad([x_i, y_i])
dx_i, dy_i = grad([x_i, y_i])
new_x_i = x_i - dx_i * step
new_y_i = y_i - dy_i * step
new_f_i = f((new_x_i, new_y_i))
new_f_i < all_f_i[-1]
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_y_i.append(y_i)
all_f_i.append(f_i)
if np.sqrt(dx_i**2 + dy_i**2).sum() < tol:   #<<
break
def grad_desc_2d(x0, f, grad, step, tau=0.5, max_step=100, max_back=10, tol = 1e-6):
x_i, y_i = x0
all_x_i = [x_i]
all_y_i = [y_i]
all_f_i = [f((x_i,y_i))]
for i in range(max_step):
dx_i, dy_i = grad([x_i, y_i])
for j in range(max_back):
new_x_i = x_i - dx_i * step
new_y_i = y_i - dy_i * step
new_f_i = f((new_x_i, new_y_i))
if (new_f_i < all_f_i[-1]):
break
step = step * tau
x_i, y_i, f_i = new_x_i, new_y_i, new_f_i
all_x_i.append(x_i)
all_y_i.append(y_i)
all_f_i.append(f_i)
if np.sqrt(dx_i**2 + dy_i**2).sum() < tol:   #<<
break
return all_x_i, all_y_i, all_f_i
f, grad, hess = mk_quad(0.7)
opt = grad_desc_2d((1.6, 1.1), f, grad, step=1)
plot_2d_traj((-1,2), (-1,2), f, title="$\\epsilon=0.7$", traj=opt)
f, grad, hess = mk_quad(0.02)
opt = grad_desc_2d((1.6, 1.1), f, grad, step=1)
plot_2d_traj((-1,2), (-1,2), f, title="$\\epsilon=0.7$", traj=opt)
f, grad, hess = mk_quad(0.7)
opt = grad_desc_2d((1.6, 1.1), f, grad, step=2)
plot_2d_traj((-1,2), (-1,2), f, title="$\\epsilon=0.7$", traj=opt)
reticulate::repl_python()
def newton_cg(x0, f, grad, hess=None, tol=1e-8):
all_x_i = [x0[0]]
all_y_i = [x0[1]]
all_f_i = [f(x0)]
def store(X):
print(X)
x, y = X
all_x_i.append(x)
all_y_i.append(y)
all_f_i.append(f(X))
optimize.minimize(
f, x0, jac=grad, hess=hess, tol=tol,
method="Newton-CG", callback=store
)
return all_x_i, all_y_i, all_f_i
def newton_cg(x0, f, grad, hess=None, tol=1e-8):
all_x_i = [x0[0]]
all_y_i = [x0[1]]
all_f_i = [f(x0)]
def store(X):
print(X)
x, y = X
all_x_i.append(x)
all_y_i.append(y)
all_f_i.append(f(X))
optimize.minimize(
f, x0, jac=grad, hess=hess, tol=tol,
method="Newton-CG", callback=store
)
return all_x_i, all_y_i, all_f_i
reticulate::repl_python()
reticulate::repl_python()
knitr::opts_chunk$set(
fig.align="center",
cache=FALSE
)
local({
hook_err_old <- knitr::knit_hooks$get("error")  # save the old hook
knitr::knit_hooks$set(error = function(x, options) {
# now do whatever you want to do with x, and pass
# the new x to the old hook
x = sub("## \n## Detailed traceback:\n.*$", "", x)
x = sub("Error in py_call_impl\\(.*?\\)\\: ", "", x)
hook_err_old(x, options)
})
hook_warn_old <- knitr::knit_hooks$get("warning")  # save the old hook
knitr::knit_hooks$set(warning = function(x, options) {
x = sub("<string>:1: ", "", x)
hook_warn_old(x, options)
})
})
reticulate::repl_python()
knitr::include_graphics("imgs/seaborn_levels.png")
reticulate::repl_python()
